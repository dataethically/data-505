---
title: "Conditional Probability"
author: "Paxton Jones"
date: "02/17/2025"

format: 
  html:  # You will quite likely want to change all but the last one, to taste
    theme: superhero  
    mainfont: monospace
    highlight-style: github
    title-block-banner: true
    embed-resources: true
---

**Abstract:**

This is a technical blog post of **both** an HTML file *and* [.qmd file](https://raw.githubusercontent.com/cd-public/D505/refs/heads/master/hws/src/cond.qmd) hosted on GitHub pages.

# 0. Quarto Type-setting

-   This document is rendered with Quarto, and configured to embed an images using the `embed-resources` option in the header.
-   If you wish to use a similar header, here's is the format specification for this document:

``` email
format: 
  html:
    embed-resources: true
```

# 1. Setup

**Step Up Code:**

```{r}
sh <- suppressPackageStartupMessages
sh(library(tidyverse))
sh(library(caret))
sh(library(tidytext))
wine <- readRDS(gzcon(url("https://github.com/cd-public/D505/raw/master/dat/pinot.rds")))
```

# 2. Conditional Probability

Calculate the probability that a Pinot comes from Burgundy given it has the word 'fruit' in the description.

$$
P({\rm Burgundy}~|~{\rm Fruit})
$$

```{r}

# Among Pinot wines, filter to those whose description contains the word 'fruit'
pinot_with_fruit <- wine %>%
  filter(str_detect(tolower(description), "fruit"))

# Probability = (# that come from Burgundy) / (# with 'fruit')
prob_burgundy_given_fruit <- mean(pinot_with_fruit$province == "Burgundy")
prob_burgundy_given_fruit
```

# 3. Naive Bayes Algorithm

We train a naive bayes algorithm to classify a wine's province using: 1. An 80-20 train-test split. 2. Three features engineered from the description 3. 5-fold cross validation.

We report Kappa after using the model to predict provinces in the holdout sample.

```{r}
wino <- wine%>%
  mutate(
    province = as.factor(wine$province)
  )

set.seed(123)

train_index <- createDataPartition(wine$province, p = 0.8, list = FALSE)

train_data <- wino[train_index, ]
test_data  <- wino[-train_index, ]

train_data <- train_data %>%
  mutate(
    has_fruit  = str_detect(tolower(description), "fruit"),
    has_smooth   = str_detect(tolower(description), "smooth"),
    has_tannin = str_detect(tolower(description), "tannin")
  )

test_data <- test_data %>%
  mutate(
    has_fruit  = str_detect(tolower(description), "fruit"),
    has_smooth    = str_detect(tolower(description), "smooth"),
    has_tannin = str_detect(tolower(description), "tannin")
  )

ctrl <- trainControl(method = "cv", number = 5)

set.seed(123)
nb_model <- train(
  province ~ (has_fruit + has_smooth + has_tannin),
  data = train_data,
  method = "naive_bayes",
  trControl = ctrl
)

nb_model

preds <- predict(nb_model, newdata = test_data)

conf_mat <- confusionMatrix(preds, test_data$province)
conf_mat$overall["Kappa"]
```

# 4. Frequency Differences

We find the three words that most distinguish New York Pinots from all other Pinots.

```{r}
# Tokenize into words
pinot_words <- wino %>%
  unnest_tokens(word, description)

pinot_words <- pinot_words %>%
 anti_join(stop_words, by = "word")

# Separate NY vs. Other
ny_pinots <- pinot_words %>%
  filter(province == "New_York")

other_pinots <- pinot_words %>%
  filter(province != "New_York")

# Count word frequencies
ny_counts <- ny_pinots %>%
  count(word, sort = TRUE) %>%
  rename(ny_n = n)

other_counts <- other_pinots %>%
  count(word, sort = TRUE) %>%
  rename(other_n = n)

# Join them and compare
freq_compare <- ny_counts %>%
  full_join(other_counts, by = "word") %>%
  replace_na(list(ny_n = 0, other_n = 0)) %>%
  mutate(
    diff_count = ny_n - other_n,
    total = ny_n + other_n
  ) %>%
  arrange(desc(abs(diff_count)))  # sort by largest absolute difference

# The three words with the largest difference
head(freq_compare, 3)
```
